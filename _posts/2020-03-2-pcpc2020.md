---
layout: posts
title: Programmazione concorrente, parallela e su cloud - Class 2019/20
category: teaching
---


<h2> Master Degree Course of prof. Vittorio Scarano and Carmine Spagnuolo, Ph.D., Università degli Studi di Salerno</h2>

- [Books and References](#books-and-references)
- [Materials for online course](#materials-for-online-course)
  - [Lessons](#lessons)
  - [Have fun with MPI in C](#have-fun-with-mpi-in-c)
  - [Class Question Forum](#class-question-forum)
- [Course Homeworks](#course-homeworks)
  - [🤔 Which is my homework ❓](#%f0%9f%a4%94-which-is-my-homework-%e2%9d%93)
  - [Homeworks list](#homeworks-list)
    - [Game of Life](#game-of-life)
    - [N-Body](#n-body)
    - [Words Count](#words-count)
  - [Give me a project now!](#give-me-a-project-now)
  - [Prepare your submission archive 📁](#prepare-your-submission-archive-%f0%9f%93%81)
    - [Submit your homework](#submit-your-homework)
- [Homework Evaluation Criteria](#homework-evaluation-criteria)
  - [Compute your score](#compute-your-score)
  - [Benchmarks TIPS](#benchmarks-tips)
  - [How benchmark your applications on a AWS?](#how-benchmark-your-applications-on-a-aws)
    - [Amazon Web Services educate supported instances](#amazon-web-services-educate-supported-instances)

# Books and References

1. Kai Hwang, Jack Dongarra, and Geoffrey C. Fox. 2011. Distributed and Cloud Computing: From Parallel Processing to the Internet of Things (1st ed.). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.
2. Czech, Z. (2017). Introduction to Parallel Computing. Cambridge: Cambridge University Press.
3. 📖 [Have fun with MPI in C](http://bit.ly/have-fun-with-mpi-in-c)

# Materials for online course

## Lessons
- 📅 02/03/2020
    - 🔗 [AWS Overview](https://spagnuolocarmine.github.io/assets/files/pcpc2020/aws-overview.pdf)
    - 🔖 [Slides A](https://spagnuolocarmine.github.io/assets/files/pcpc2020/02032020_a.pdf)
    - 🔖 [Slides B](https://spagnuolocarmine.github.io/assets/files/pcpc2020/02032020_b.pdf)
- 📅 16/03/2020
    - 🔖 [Slides](https://spagnuolocarmine.github.io/assets/files/pcpc2020/16032020.pdf)
    - 🔗 [![Public class chat https://gitter.im/isislab-unisa/pcpc2020](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/isislab-unisa/pcpc2020?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge) <span style="color:red">**(dismissed)**</h3Master>
    -  🔗 [![Discord](https://img.shields.io/discord/693092516286693387.svg?label=&logo=discord&logoColor=ffffff&color=7389D8&labelColor=6A7EC2)](https://discord.gg/BTt5fUp) ISISLab Community
       -  Channel **#pcpc**
    - 🛠 [Install OpenMPI on Linux Ubuntu](https://github.com/spagnuolocarmine/ubuntu-openmpi-openmp)
- 📅 20/03/2020
    - ⚙️ [Counting sort](https://spagnuolocarmine.github.io/news/counting-sort/)
    - 🔖 [Slides A](https://spagnuolocarmine.github.io/assets/files/pcpc2020/20032020_a.pdf)
    - 🔖 [Slides B](https://spagnuolocarmine.github.io/assets/files/pcpc2020/20032020_b.pdf)
- 📅 23/03/2020
    - 🔖 [Slides](https://spagnuolocarmine.github.io/assets/files/pcpc2020/23032020.pdf)
    - 🐳 [Docker Ubuntu OpenMPI](https://hub.docker.com/r/spagnuolocarmine/docker-mpi)
    - 🆘 [Usage Docker environment](https://tech.io/playgrounds/47058/have-fun-with-mpi-in-c/docker-mpi-environment)
- 📅 27/03/2020
    - 🔖 [Slides](https://spagnuolocarmine.github.io/assets/files/pcpc2020/27032020.pdf)
    - 📖 [Have fun with MPI in C](http://bit.ly/have-fun-with-mpi-in-c)
        - 📌 Chapter 1 - [Introduction](https://tech.io/playgrounds/47058/have-fun-with-mpi-in-c/lets-start-to-have-fun-with-mpi)
    - 🔗 [MPI 3.1 Official Documentation](https://spagnuolocarmine.github.io/assets/files/pcpc2020/mpi31-report.pdf)
    - 🧮 [Hello World](https://spagnuolocarmine.github.io/assets/files/pcpc2020/hello_world.c) source code.
    - 🧮 [Hello World, Have fun with MPI in C](https://spagnuolocarmine.github.io/assets/files/pcpc2020/hello_world_have_fun_with_mpi.c) source code.
- 📅 30/03/2020
    - 🔖 [Slides](https://spagnuolocarmine.github.io/assets/files/pcpc2020/30032020.pdf)
    - 📖 [Have fun with MPI in C](http://bit.ly/have-fun-with-mpi-in-c)
        - 📌 Chapter 2.1 - [MPI Memory Model](https://tech.io/playgrounds/47058/have-fun-with-mpi-in-c/mpi-memory-model)
        - 📌 Chapter 2.2 - [Blocking Communication](https://tech.io/playgrounds/47058/have-fun-with-mpi-in-c/blocking-communication)
    - 📓 [Homework 1](https://spagnuolocarmine.github.io/assets/files/pcpc2020/e30032020.pdf)
- 📅 03/04/2020
    - 🔖 [Slides](https://spagnuolocarmine.github.io/assets/files/pcpc2020/03042020.pdf)
    - 📖 [Have fun with MPI in C](http://bit.ly/have-fun-with-mpi-in-c)
        - 📌 Chapter 2.3 - [Communication Modes](https://tech.io/playgrounds/47058/have-fun-with-mpi-in-c/communication-modes)
        - 📌 Chapter 2.4 - [Non-Blocking Communication](https://tech.io/playgrounds/47058/have-fun-with-mpi-in-c/non-blocking-communication)
     - 📓 [Homework 2](https://spagnuolocarmine.github.io/assets/files/pcpc2020/e03042020.pdf)
- 📅 06/04/2020
    - 📓 [Homework 3](https://spagnuolocarmine.github.io/assets/files/pcpc2020/e06042020.pdf)
- 📅 17/04/2020
    - 🔖 [Slides](https://spagnuolocarmine.github.io/assets/files/pcpc2020/17042020.pdf)
    - 📖 [Have fun with MPI in C](http://bit.ly/have-fun-with-mpi-in-c)
        - 📌 Chapter 4 - [Collective Communication](https://tech.io/playgrounds/47058/have-fun-with-mpi-in-c/collective-communications-overview)
     - 📓 [Homework 4](https://spagnuolocarmine.github.io/assets/files/pcpc2020/e17042020.pdf)
- 📅 20/04/2020
    - 📖 [Have fun with MPI in C](http://bit.ly/have-fun-with-mpi-in-c)
        - 📌 Chapter 3 - [Communicate Noncontiguous Data](https://tech.io/playgrounds/29504739e1d9dae30ea1abacc9889fc385074/have-fun-with-mpi-in-c/communicate-noncontiguous-data)
     - 📓 [Homework 5](https://spagnuolocarmine.github.io/assets/files/pcpc2020/e20042020.pdf)
    
## Have fun with MPI in C
```c 
#include <stdio.h>
#include <mpi.h>
#include <string.h>
static const char NERD[5] =  {0xF0, 0x9F, 0xA4, 0x93, '\0'};
static const char WORLD[5] =  {0xF0, 0x9F, 0x8C, 0x8D, '\0'};
static const char SLEEP[5] =  {	0xF0, 0x9F, 0x98, 0xB4, '\0'};
#define 🤓 {MPI_Init(NULL, NULL);  int world_rank; MPI_Comm_rank(MPI_COMM_WORLD, &world_rank); printf("I am the %s with rank %d ",NERD, world_rank);}
#define 🌍 ({int s; MPI_Comm_size(MPI_COMM_WORLD, &s); printf("of MPI %s of size %d ", WORLD, s);});
#define 😴 {printf("Goodbye %s\n",SLEEP);MPI_Finalize();return 0;}
#define P(x) printf(x)
#define I P("\a");
#define am P("\a");
#define the P("\a");
#define with P("\a");
#define rank P("\a");
#define size P("\a");
#define 🤔 {P("\a");};
#define of P("\a");
#define MPI P("\a");
#define Goodbye P("\a");
int main()
{  
	I am the 🤓 with rank 🤔 of MPI 🌍 of size 🤔 Goodbye 😴;
}
```


## Class Question Forum

- [![Discord](https://img.shields.io/discord/693092516286693387.svg?label=&logo=discord&logoColor=ffffff&color=7389D8&labelColor=6A7EC2)](https://discord.gg/BTt5fUp) ISISLab Community
       -  Channel **#pcpc**
- Moreover, we use issues on [GitHub](https://github.com/spagnuolocarmine/spagnuolocarmine.github.io/issues). Please use it for sharing ideas and issues on both theoretical and practical course part.

-------------------------------------------------------------------------------------------------

# Course Homeworks

## 🤔 Which is my homework ❓

Each student must develop a solution for the assigned homework using parallel programming approach, exploiting  distributed memory. The solution must be written in C programming language exploiting OpenMPI, using point-to-point and/or collective communication. The developed solution must experiment on a homogeneous cluster scenario on Amazon Web Services. 

The cluster must be created on the Amazon Web Services using a supported [AWS Educate Instances](https://s3.amazonaws.com/awseducate-starter-account-services/AWS_Educate_Starter_Accounts_and_AWS_Services.pdf). The obtained results must be presented in terms of [strong and weak scalability](https://www.sharcnet.ca/help/index.php/Measuring_Parallel_Scaling_Performance), varying the number of computing processors from _1_ to _NUMBER-OF-VCPU-FOR-INSTANCE-TYPE_ _x_ _NUMBER-OF-INSTANCES_. For example, if we run a cluster machine of _4_ t2.large (2 VCPU) nodes, we have to perform the scalability of our solution for P={1,2,4,5,6,7,8}.
 
 
The total number of processors is equal to the number of Virtual CPU on the running instances. The benchmark must exploit **8** instances for the bigger experiment. The student must describe the solution and the benchmark in a README file, written in Markdown, and included in the submission in both the format Markdown and PDF. The README file must describes also the compilation phase and how to reproduce the results obtained, considering the Docker MPI environment of the course.

## Homeworks list 

ID | Name | Description
------- | ------- | -------
1 | [_gameoflife_](#game-of-life) | Conway's Game of Life Game 
2 | [_nbody_](#n-body) | N-body problem 
3 | [_wordscount_ ](#words-count)| Compute the frequency of words in a set of files 

### Game of Life


The Game of Life, also known simply as Life, is a cellular automaton devised by the British mathematician John Horton Conway in 1970.
The "game" is a zero-player game, meaning that its evolution is determined by its initial state, requiring no further input. One interacts with the Game of Life by creating an initial configuration and observing how it evolves, or, for advanced "players", by creating patterns with particular properties.


<img src="https://upload.wikimedia.org/wikipedia/commons/e/e5/Gospers_glider_gun.gif" alt="nbody" width="200" style="margin: 10px auto 20px; display: block;" />


The universe of the Game of Life is an infinite two-dimensional orthogonal grid of square cells, each of which is in one of two possible states, alive or dead, or "populated" or "unpopulated". 

Every cell interacts with its eight neighbours, which are the cells that are horizontally, vertically, or diagonally adjacent. At each step in time, the following transitions occur:

- Any live cell with fewer than **2** live neighbours dies, as if caused by underpopulation.
- Any live cell with **2** or **3** live neighbours lives on to the next generation.
- Any live cell with more than **3** live neighbours dies, as if by overpopulation.
- Any dead cell with exactly **3** live neighbours becomes a live cell, as if by reproduction.

The initial pattern constitutes the seed of the system. The first generation is created by applying the above rules simultaneously to every cell in the seed—births and deaths occur simultaneously, and the discrete moment at which this happens is sometimes called a tick (in other words, each generation is a pure function of the preceding one). The rules continue to be applied repeatedly to create further generations.


### N-Body

In an n-body problem, we need to find the positions and velocities of a collection of interacting particles over a period of time. For example, an astrophysicist might want to know the positions and velocities of a collection of stars, while a chemist might want to know the positions and velocities of a collection of molecules or atoms.

<img src="https://mir-s3-cdn-cf.behance.net/project_modules/disp/b15a1122638879.56315fcc653b5.gif" alt="nbody" width="200"style="margin: 10px auto 20px; display: block;" />


An n-body solver is a program that finds the solution to an n-body problem by simulating the behavior of the particles. The input to the problem is the mass, position, and velocity of each particle at the start of the simulation, and the output is typically the position and velocity of each particle at a sequence of user-specified times, or simply the position and velocity of each particle at the end of a user-specified time period.

The problem is described [here](https://en.wikipedia.org/wiki/N-body_simulation).

**N^2 Solution** Consider only the solution that is quadratic in the number of particles.

[Example Solution Sequential](https://github.com/harrism/mini-nbody/blob/master/nbody.c)

### Words Count

<img src="https://raw.githubusercontent.com/spagnuolocarmine/spagnuolocarmine.github.io/master/assets/img/words.gif" alt="wordscount" width="200" style="margin: 10px auto 20px; display: block;" />



We will be doing a version of map-reduce using MPI to perform word counting over a large number of files. There are 3 steps to this process:
1) is to read in the master file list which will contain the names of all the files that are to be counted. Note that only 1 of your processes should read this file. Then each of the processes should receive their portion of the file from the master process. Once a process has received its list of files to process, it should then read in each of the files and perform a word counting, keeping track of the frequency each word found in the files occurs. We will call the histogram produced the local histogram. This is similar to the map stage or map-reduce.
2) is to then combine frequencies of words across processes. For example the word 'cat' might be counted in multiple processes and we need to add up all these occurrences. This is similar to the reduce stage of map-reduce. 
3) is to have each of the processes send their local histograms to the master process. The master process just needs to gather up all this information. Note that there will be duplicate words between processes. The master should then print out the results to the screen.



## Give me a project now!
 
Compute the MD5 of your name, surname, and birth date, ```md5(namesurnamedate)```:

- the first character in the MD5 is the homework;
- the last character in the MD5 is the AWS EC2 instance type for your cluster environment.

Characters table conversion (use case insentive):

| Project Character |Value|
|---|---|
|a-g-m-s-y-4-b-h-n-t-z-5|1|
|c-i-o-u-0-6-d-j-p-v-1-7|2|
|e-k-q-w-2-8-f-l-r-x-3-9|3|


| Instance Type Character |Value|
|---|---|
|a-g-m-s-y-4|1|
|b-h-n-t-z-5|2|
|c-i-o-u-0-6|3|
|d-j-p-v-1-7|4|
|e-k-q-w-2-8|5|
|f-l-r-x-3-9|6|


**Example** 

Alice Wonderland 01/01/1865, your assignment is _alicewonderland01011865_, ```md5(alicewonderland01011865)=89820e2ce860966ccd9165e4029035e7```, that is solve the _wordscount_ problem on _t2.2xlarge_ instances.


## Prepare your submission archive 📁 

Each solution folder must contain the C sources and a report file (in Markdown format and PDF) describing all benchmarks (expressed in terms of strong and weak scalability) of the application. 

⚠️ Solutions without the Readme file or that cannot easily compile using mpicc will be not considered.

In your home project directory archives your project:
```
tar -cvf solution.tar.gz *
```
Extract your project:
```
tar -xvf solution.tar.gz
```

### Submit your homework

- Each solution should be compliant with the problem project template. 
- You can submit a solution via mail to cspagnuolo+PCPC-2019@unisa.it. 
  - The submitted file should be:
    -  a compressed directory using tape archive,
    -  a public GitHub repository (⭐️ preferred), 
    -  or any kind of easily accessible method.
- ⚠ <span style="color:red"> The submission deadline is the day of the official exam on the ESSE3 platform.</span>

# Homework Evaluation Criteria

Homeworks are evaluated on a range of 30 total points. The final score is expressed in the following four level:

Level | Range
------- | -------
**A** | [30-28]
**B** | [27-25]
**C** | [24-22]
**D** | [21-18]

## Compute your score

- **Correctness**. 0 to 10 points. Measures the student's commitment to develop a solution that is compliant with the problem requirement (obviously!). But also solution that solve part of the problem can be evaluated, if it is clear that only minor part of the problem are not correctly solved.
- **Style**. 0 to 10 points. Measures the student's commitment to develop a solution styling it and exploiting all features of MPI and C language, paying attention to use arguments of the parallel and concurrent computing fundamental part.
- **Problem evaluation and Benchamrks**. 0 to 10 points. Measures the student's commitment to undestand the problem and give a good solution, moreover, mesures the student's commitment to presents a deeply analysis of the program performance.

## Benchmarks TIPS 

Present your results in terms of strong and week scalability:

- **Strong Scalability**: How fast the problem size must increase in order to maintain a fixed efficiency when the number of
processes is increased. In practice the total problem size stays the same as the number of processors increases.  Goal: Minimize time to solution for a given problem.
- **Weak Scalability**: How fast the efficiency decreases when the number of processes increases but the problem size is fixed. In practice  the problem size increases at the same rate as the number of processors, keeping the amount of work per processor equal. Goal: solve the larger problems.


## How benchmark your applications on a AWS? 

All information are available at this [repository](https://github.com/spagnuolocarmine/ubuntu-openmpi-openmp).


### Amazon Web Services educate supported instances

At this [link](https://s3.amazonaws.com/awseducate-starter-account-services/AWS_Educate_Starter_Accounts_and_AWS_Services.pdf) are described all limitations for the Amazon Educate program.


ID | EC2 Instance name
------- | -------
1 | t2.small
2 | t2.large
3 | t2.xlarge
4 | t2.2xlarge
5 | m4.large
6 | m4.xlarge

<!--
### Project Request
<iframe src="https://docs.google.com/forms/d/e/1FAIpQLScw6qbFwtbFc0EaCc4iLRTyo_1H46uWiDc-JMsGI0-3au1u1A/viewform?embedded=true" width="640" height="1239" frameborder="0" marginheight="0" marginwidth="0">Caricamento in corso...</iframe>

-->
