---
layout: posts
title: Programmazione concorrente, parallela e su cloud - Class 2019/20
category: teaching
---

### Master Degree Course of prof. Vittorio Scarano and Carmine Spagnuolo, Ph.D., Universit√† degli Studi di Salerno
-------------------------------------------------------------------------

## Books and References

1. Kai Hwang, Jack Dongarra, and Geoffrey C. Fox. 2011. Distributed and Cloud Computing: From Parallel Processing to the Internet of Things (1st ed.). Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.
2. Czech, Z. (2017). Introduction to Parallel Computing. Cambridge: Cambridge University Press.

## Materials for online course
- üìÖ 02/03/2020
    - üîó [AWS Overview](https://spagnuolocarmine.github.io/assets/files/pcpc2020/aws-overview.pdf)
    - üîñ [Slides A](https://spagnuolocarmine.github.io/assets/files/pcpc2020/02032020_a.pdf)
    - üîñ [Slides B](https://spagnuolocarmine.github.io/assets/files/pcpc2020/02032020_b.pdf)
- üìÖ 16/03/2020
    - üîñ [Slides](https://spagnuolocarmine.github.io/assets/files/pcpc2020/16032020.pdf)
    - üîó Public class chat room [![Public class chat https://gitter.im/isislab-unisa/pcpc2020](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/isislab-unisa/pcpc2020?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge) 
    - üõ† [Install OpenMPI on Linux Ubuntu](https://github.com/spagnuolocarmine/ubuntu-openmpi-openmp)
- üìÖ 20/03/2020
    - ‚öôÔ∏è [Counting sort](https://spagnuolocarmine.github.io/news/counting-sort/)
    - üîñ [Slides A](https://spagnuolocarmine.github.io/assets/files/pcpc2020/20032020_a.pdf)
    - üîñ [Slides B](https://spagnuolocarmine.github.io/assets/files/pcpc2020/20032020_b.pdf)
- üìÖ 23/03/2020
    - üîñ [Slides](https://spagnuolocarmine.github.io/assets/files/pcpc2020/23032020.pdf)
    - üê≥ [Docker Ubuntu OpenMPI](https://hub.docker.com/r/spagnuolocarmine/docker-mpi)
    - üÜò Usage Docker environment: ```docker run -it --mount src="$(pwd)",target=/home,type=bind spagnuolocarmine/docker-mpi:latest```, executes the docker container, which mounts the current path in the ```/home``` folder of the container. However, in order to run the container (using the user root), you need to allow the execution of the ```mpirun``` command using the root user by adding the ```--allow-run-as-root``` option, for instance ```mpirun --allow-run-as-root -np 3 myprogram.out```.
- üìÖ 27/03/2020
    - üîñ [Slides](https://spagnuolocarmine.github.io/assets/files/pcpc2020/27032020.pdf)
    - üìñ [Have fun with MPI in C](http://bit.ly/have-fun-with-mpi-in-c)
        - üìå Chapter 1 - [Introduction](https://tech.io/playgrounds/47058/have-fun-with-mpi-in-c/lets-start-to-have-fun-with-mpi)
    - üìÉ [Hello World](https://spagnuolocarmine.github.io/assets/files/pcpc2020/hello_world.c) source code.
    - üìú [Hello World, Have fun with MPI in C](https://spagnuolocarmine.github.io/assets/files/pcpc2020/hello_world_have_fun_with_mpi.c) source code.


## Class Question Forum

We use issues on [GitHub](https://github.com/spagnuolocarmine/spagnuolocarmine.github.io/issues). Please use it for sharing ideas and issues on both theoretical and practical course part.

-------------------------------------------------------------------------------------------------

# Homeworks

## Which is my homework?

Each student must develop a solution for the assigned homework using Hybrid parallel programming approach, exploiting shared and distributed memory. The solution must be written in C programming language exploiting OpenMPI, using point-to-point and/or collective communication. The developed solution must experiment on a homogeneous cluster scenario. 

The cluster must be created on the Amazon Web Services using a supported [AWS Educate Instances](https://s3.amazonaws.com/awseducate-starter-account-services/AWS_Educate_Starter_Accounts_and_AWS_Services.pdf). The obtained results must be presented in terms of [strong and weak scalability](https://www.sharcnet.ca/help/index.php/Measuring_Parallel_Scaling_Performance), varying the number of computing processors from _1_ to _NUMBER-OF-VCPU-FOR-INSTANCE-TYPE_ _x_ _NUMBER-OF-INSTANCES_. For example, if we run a cluster machine of _4_ t2.large (2 VCPU) nodes, we have to perform the scalability of our solution for P={1,2,4,5,6,7,8}.
 
 
The total number of processors is equal to the number of Virtual CPU on the running instances. The benchmark must exploit **8** instances for the bigger experiment. The student must describe the solution and the benchmark in a README file, written in Markdown, and included in the submission. The README file must describe also the compilation phase and how to reproduce the results obtained.

### Homeworks list

| Name |  Description | Details | 
|---|---|---|
| _gameoflife_ | Conway's Game of Life Game |[link](https://spagnuolocarmine.github.io/teaching/pcpc/gol)|
| _jacobi_ |  Simple Jacobi iteration |[link](https://spagnuolocarmine.github.io/teaching/pcpc/jacobi)|
| _matrixmultiplication_  |  Parallel matrix multiplication |[link](https://spagnuolocarmine.github.io/teaching/pcpc/matrix)|
| _nbody_|  n-body problem |[link](https://spagnuolocarmine.github.io/teaching/pcpc/nbody)|
| _pi_ |  Compute in parallel an approximation of PI |[link](https://spagnuolocarmine.github.io/teaching/pcpc/pi)|
| _wordscount_ | Compute the frequency of words in a set of files |[link](https://spagnuolocarmine.github.io/teaching/pcpc/wordscount)|

### Amazon Web Services educate supported instances

1. t2.small
2. t2.large
3. t2.xlarge
4. t2.2xlarge
5. m4.large
6. m4.xlarge

## Give me a project now!
 
Compute the MD5 of your name, surname, and birth date, ```md5(namesurnamedate)```:

- the first character in the MD5 is the homework;
- the last character in the MD5 is the AWS EC2 instance type for your cluster environment.

Characters table conversion (use case insentive):

| Character |Value|
|---|---|
|a-g-m-s-y-4|1|
|b-h-n-t-z-5|2|
|c-i-o-u-0-6|3|
|d-j-p-v-1-7|4|
|e-k-q-w-2-8|5|
|f-l-r-x-3-9|6|

**Example** Alice Wonderland 01/01/1865, your assignment is _alicewonderland01011865_, ```md5(alicewonderland01011865)=89820e2ce860966ccd9165e4029035e7```, that is solve the _pi_ problem on _t2.2xlarge_ instances.


## Prepare your submission

Each solution folder must contain the C sources and a report Readme file (in Markdown format) describing all benchmarks (expressed in terms of strong and weak scalability) of the application. Solutions without the Readme file or that cannot easily compile using mpicc will be not considered.

In your home project directory archives your project:
```
tar -cvf solution.tar.gz *
```
Extract your project:
```
tar -xvf solution.tar.gz
```

### Submit a solution

Each solution should be compliant with the problem project template. You can submit a solution via mail to cspagnuolo+PCPC-2019@unisa.it. The submitted file should be a compressed directory using tape archive.


# Homework Evaluation Criteria

Homeworks are evaluated on a range of 30 total points. The final score is diveded in four level:

- **A** [30-28]
- **B** [27-25]
- **C** [24-22]
- **D** [21-18]

## Points

- **Correctness**. 0 to 10 points. Measures the student's commitment to develop a solution that is compliant with the problem requirement (obviously!). But also solution that solve part of the problem can be evaluated, if it is clear that only minor part of the problem are not correctly solved.
- **Style**. 0 to 10 points. Measures the student's commitment to develop a solution styling it and exploiting all features of MPI and C language, paying attention to use arguments of the parallel and concurrent computing fundamental part. Moreover, the ability to use other MPI features not presented during the course will be evaluated (ref.  Cap 4-6-7 [MPI 2.2](https://www.mpi-forum.org/docs/mpi-2.2/mpi22-report.pdf)).
- **Problem evaluation and Benchamrks**. 0 to 10 points. Measures the student's commitment to undestand the problem and give a good solution, moreover, mesures the student's commitment to presents benchamrks.
- **Lateness**. The total score is decreased by 5% each day, until a 40% eight days or more late. The homework _must_ be subitted for review 8 days before the exam date.

## Benchmarks TIPS 

Present your results in terms of strong and week scalability:

- **Strong Scalability**: How fast the problem size must increase in order to maintain a fixed efficiency when the number of
processes is increased. In practice the total problem size stays the same as the number of processors increases.  Goal: Minimize time to solution for a given problem.
- **Weak Scalability**: How fast the efficiency decreases when the number of processes increases but the problem size is fixed. In practice  the problem size increases at the same rate as the number of processors, keeping the amount of work per processor equal. Goal: solve the larger problems.


-------------------------------------------------------------------------------------------------------------------------

# How benchmark your applications on a AWS? 

All information are available at this [repository](https://github.com/spagnuolocarmine/ubuntu-openmpi-openmp).

<!--
### Project Request
<iframe src="https://docs.google.com/forms/d/e/1FAIpQLScw6qbFwtbFc0EaCc4iLRTyo_1H46uWiDc-JMsGI0-3au1u1A/viewform?embedded=true" width="640" height="1239" frameborder="0" marginheight="0" marginwidth="0">Caricamento in corso...</iframe>

-->
